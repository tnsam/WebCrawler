{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Cralwer based on keywords.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "44REQyjvV8Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TWoLJ7-VzPZ"
      },
      "outputs": [],
      "source": [
        "# install chromium, its driver, and selenium\n",
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium\n",
        "# set options to be headless, ..\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import pathlib\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from pytz import timezone\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "def crawl_content(url, keywords) :\n",
        "  driver = webdriver.Chrome('chromedriver',options=options)  \n",
        "  driver.get(url)\n",
        "\n",
        "  # Wait for initialize, in seconds\n",
        "  wait = WebDriverWait(driver, 20)\n",
        "\n",
        "  #search for keywords\n",
        "  search = driver.find_element_by_xpath('//*[@id=\"header\"]/div/nav/form/div/input')\n",
        "  search.send_keys(keywords)\n",
        "  search.send_keys(Keys.RETURN)  \n",
        "\n",
        "  time.sleep(8)\n",
        "\n",
        "  article_list = []\n",
        "  nextPage = True  \n",
        "  count = 0\n",
        "  while nextPage:   \n",
        "  # while nextPage and count < 3:\n",
        "    time.sleep(8)\n",
        "    all_news_link = driver.find_elements_by_css_selector(\"a.d-flex.article.listing.mb-3.pb-3\")\n",
        "\n",
        "    listOflinks=[]\n",
        "    for el in all_news_link:\n",
        "      link = el.get_property('href')\n",
        "      listOflinks.append(link)\n",
        "\n",
        "    all_field_category = driver.find_elements_by_css_selector('span.field-category') \n",
        "    \n",
        "    listOfField = []\n",
        "    for i in all_field_category:\n",
        "      listOfField.append(i.text)\n",
        "\n",
        "    time.sleep(8)\n",
        "\n",
        "    #check the last news article crawled\n",
        "    csv_file_checking = '/content/drive/Shared drives/NLP Assignment/checking_news.csv'\n",
        "    file = pathlib.Path(csv_file)\n",
        "    file2 = pathlib.Path(csv_file_checking)    \n",
        "    valid = True\n",
        "    condition = False\n",
        "    i = 0\n",
        "    while (i < len(listOflinks)) and valid:   \n",
        "      driver.get(listOflinks[i])\n",
        "      time.sleep(8)\n",
        "\n",
        "      field_category = listOfField[i]\n",
        "\n",
        "      reload = True\n",
        "      while reload:\n",
        "        try:\n",
        "          time_created = driver.execute_script(\"return document.querySelector('div.article-meta > div:last-child').innerText.split('-').pop().trim();\")\n",
        "          time.sleep(5)\n",
        "          time_created = datetime.strptime(time_created, '%B %d, %Y  @ %I:%M%p')\n",
        "          reload = False\n",
        "        except:\n",
        "          reload = True\n",
        "\n",
        "      timezone = pytz.timezone(\"Asia/Kuala_Lumpur\")\n",
        "      time_created = time_created.astimezone(timezone)\n",
        "      time_created = time_created.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "      #title\n",
        "      title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#main > div > div > div.col > div:nth-child(1) > div > h1 > span\"))).text\n",
        "      \n",
        "      #author\n",
        "      try : \n",
        "        author =  wait.until(EC.presence_of_element_located((By.XPATH,\"//*[@id='main']/div/div/div[1]/div[1]/div/div/div[1]/div[1]/div/span/a\"))).text\n",
        "      \n",
        "      except:\n",
        "        author = \" \"\n",
        "    \n",
        "      #content\n",
        "      content = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME,\"p\")))\n",
        "\n",
        "      all_content = []\n",
        "\n",
        "      for j in content:\n",
        "        all_content.append(j.text)\n",
        "      \n",
        "      if file2.exists():\n",
        "        existed_news = pd.read_csv(csv_file_checking)\n",
        "\n",
        "        record = existed_news[existed_news['Keyword'] == keywords]\n",
        "        if len(record.index) != 0 :\n",
        "          existed_date = record['Time Created'].iloc[0]\n",
        "          existed_title = record['Title'].iloc[0]\n",
        "\n",
        "          date_time = datetime.strptime(time_created, \"%Y-%m-%d %H:%M:%S\")\n",
        "          exist_date = datetime.strptime(existed_date, \"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "          if (date_time >= exist_date) and (title not in existed_title):\n",
        "            valid = True\n",
        "            article_details = {'Keyword': keywords, 'Category': field_category, 'Time Created': time_created, 'Title' : title, 'Author' : author, 'Content' : all_content}\n",
        "            article_list.append(article_details)\n",
        "\n",
        "            if i == (len(listOflinks)-1):\n",
        "              condition = True\n",
        "\n",
        "            else:\n",
        "              condition = False\n",
        "\n",
        "          else:\n",
        "            valid = False \n",
        "            condition = False\n",
        "        \n",
        "        else:\n",
        "          article_details = {'Keyword': keywords, 'Category': field_category, 'Time Created': time_created, 'Title' : title, 'Author' : author, 'Content' : all_content}\n",
        "          article_list.append(article_details)    \n",
        "          condition = True\n",
        "\n",
        "      else:\n",
        "        article_details = {'Keyword': keywords, 'Category': field_category, 'Time Created': time_created, 'Title' : title, 'Author' : author, 'Content' : all_content}\n",
        "        article_list.append(article_details)\n",
        "        condition = True\n",
        "\n",
        "      i += 1    \n",
        "\n",
        "    if condition:\n",
        "      driver.get(url)      \n",
        "\n",
        "      #search for keywords\n",
        "      search = driver.find_element_by_xpath('//*[@id=\"header\"]/div/nav/form/div/input')\n",
        "      search.send_keys(keywords)\n",
        "      search.send_keys(Keys.RETURN)  \n",
        "      time.sleep(8)\n",
        "          \n",
        "      count += 1\n",
        "      a = 0 \n",
        "      while a < count:\n",
        "        try:\n",
        "          #go to next page\n",
        "          next_button = driver.find_element_by_css_selector(\"#main > div > div.row > div.col > nav > ul > li.page-item.ml-auto > a\")\n",
        "          next_button.click()\n",
        "        except:\n",
        "          break\n",
        "        \n",
        "        a += 1\n",
        "\n",
        "    else:\n",
        "      nextPage = False\n",
        "\n",
        "  if article_list != []:\n",
        "    results = pd.DataFrame(article_list)\n",
        "    results[\"Time Created\"] = pd.to_datetime(results[\"Time Created\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "    results = results.sort_values(by=\"Time Created\")\n",
        "  \n",
        "    if file.exists ():\n",
        "        results.to_csv(csv_file, mode = 'a', index=False, header = False)\n",
        "    else:\n",
        "        results.to_csv(csv_file, index=False)\n",
        "            \n",
        "    last_row = pd.DataFrame(results.tail(1))\n",
        "    if file2.exists ():\n",
        "      record = existed_news[existed_news['Keyword'] == keywords]\n",
        "      if len(record) != 0:\n",
        "        last_record_datetime = last_row['Time Created'].iloc[0]\n",
        "\n",
        "        existed_news.loc[existed_news[\"Keyword\"] == keywords, 'Time Created'] = last_record_datetime\n",
        "        existed_news.loc[existed_news[\"Keyword\"] == keywords, 'Title'] = last_row['Title'].iloc[0]\n",
        "        existed_news.to_csv(csv_file_checking, index=False)\n",
        "\n",
        "      else:\n",
        "        last_row.to_csv(csv_file_checking, mode = 'a', index=False, header = False)\n",
        "\n",
        "    else:\n",
        "      last_row.to_csv(csv_file_checking, index=False)\n",
        "\n",
        "csv_file = '/content/drive/Shared drives/NLP Assignment/news.csv' \n",
        "crawl_content('https://www.nst.com.my/','Covid-19')\n",
        "\n",
        "final_results = pd.read_csv('/content/drive/Shared drives/NLP Assignment/news.csv')\n",
        "final_results[\"Time Created\"] = pd.to_datetime(final_results[\"Time Created\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "final_results = final_results.sort_values(by=\"Time Created\")\n",
        "final_results = final_results.drop_duplicates(subset =\"Title\",keep = False)\n",
        "final_results.to_csv(csv_file, index=False)"
      ],
      "metadata": {
        "id": "O5HopHztV4c3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}